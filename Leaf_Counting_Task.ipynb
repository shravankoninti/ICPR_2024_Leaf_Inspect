{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c191d30-8a7d-4efc-9972-a0a15506e887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> SEEDING DONE\n",
      "Leaf count data without headers:\n",
      "           0  1\n",
      "0  00001.png  6\n",
      "1  00002.png  6\n",
      "2  00003.png  6\n",
      "3  00004.png  9\n",
      "4  00005.png  7\n",
      "Leaf count data with assigned headers:\n",
      "       image  leaf_count\n",
      "0  00001.png           6\n",
      "1  00002.png           6\n",
      "2  00003.png           6\n",
      "3  00004.png           9\n",
      "4  00005.png           7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shravan/anaconda3/envs/xeek_env/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/shravan/anaconda3/envs/xeek_env/lib/python3.10/site-packages/transformers/models/vit/feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
      "  warnings.warn(\n",
      "100%|███████████████████████████████████████████| 20/20 [00:03<00:00,  6.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Model: microsoft/swin-base-patch4-window12-384, Train Loss: 314.7393, Val Loss: 210.8609, Val MAE: 9.8476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:05<00:00,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Model: microsoft/swin-base-patch4-window12-384, Train Loss: 227.7129, Val Loss: 98.7308, Val MAE: 5.6275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:03<00:00,  6.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20, Model: microsoft/swin-base-patch4-window12-384, Train Loss: 169.4867, Val Loss: 103.3170, Val MAE: 5.7385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:05<00:00,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20, Model: microsoft/swin-base-patch4-window12-384, Train Loss: 83.9297, Val Loss: 77.7683, Val MAE: 5.5132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:03<00:00,  6.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20, Model: microsoft/swin-base-patch4-window12-384, Train Loss: 87.0735, Val Loss: 79.2054, Val MAE: 5.1886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:05<00:00,  3.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20, Model: microsoft/swin-base-patch4-window12-384, Train Loss: 80.4751, Val Loss: 83.7389, Val MAE: 6.4636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:03<00:00,  6.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20, Model: microsoft/swin-base-patch4-window12-384, Train Loss: 74.1781, Val Loss: 75.5837, Val MAE: 5.1310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:05<00:00,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20, Model: microsoft/swin-base-patch4-window12-384, Train Loss: 67.9567, Val Loss: 73.0018, Val MAE: 5.0291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:03<00:00,  6.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20, Model: microsoft/swin-base-patch4-window12-384, Train Loss: 71.6880, Val Loss: 74.4512, Val MAE: 4.9258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:05<00:00,  3.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20, Model: microsoft/swin-base-patch4-window12-384, Train Loss: 66.0474, Val Loss: 55.4830, Val MAE: 4.2748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:03<00:00,  6.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20, Model: microsoft/swin-base-patch4-window12-384, Train Loss: 65.4921, Val Loss: 74.4795, Val MAE: 4.9761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:05<00:00,  3.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20, Model: microsoft/swin-base-patch4-window12-384, Train Loss: 52.3544, Val Loss: 36.6657, Val MAE: 3.5295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:03<00:00,  6.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20, Model: microsoft/swin-base-patch4-window12-384, Train Loss: 65.3976, Val Loss: 73.6092, Val MAE: 4.9690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:05<00:00,  3.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20, Model: microsoft/swin-base-patch4-window12-384, Train Loss: 44.6263, Val Loss: 34.3216, Val MAE: 3.4867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:03<00:00,  6.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20, Model: microsoft/swin-base-patch4-window12-384, Train Loss: 66.1318, Val Loss: 73.8043, Val MAE: 5.0684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:05<00:00,  3.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20, Model: microsoft/swin-base-patch4-window12-384, Train Loss: 45.5771, Val Loss: 30.6722, Val MAE: 3.2346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:03<00:00,  6.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20, Model: microsoft/swin-base-patch4-window12-384, Train Loss: 66.8283, Val Loss: 73.0219, Val MAE: 4.8958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:05<00:00,  3.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20, Model: microsoft/swin-base-patch4-window12-384, Train Loss: 40.0696, Val Loss: 30.3510, Val MAE: 3.0435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:03<00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20, Model: microsoft/swin-base-patch4-window12-384, Train Loss: 62.1929, Val Loss: 72.0899, Val MAE: 4.9763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:05<00:00,  3.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20, Model: microsoft/swin-base-patch4-window12-384, Train Loss: 37.4481, Val Loss: 30.1623, Val MAE: 3.0552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:03<00:00,  6.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20, Model: microsoft/swin-base-patch4-window12-384, Train Loss: 64.2261, Val Loss: 72.2020, Val MAE: 4.9659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:05<00:00,  3.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20, Model: microsoft/swin-base-patch4-window12-384, Train Loss: 37.3413, Val Loss: 31.6280, Val MAE: 3.2305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:03<00:00,  6.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20, Model: microsoft/swin-base-patch4-window12-384, Train Loss: 60.9335, Val Loss: 70.2587, Val MAE: 4.7713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:05<00:00,  3.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20, Model: microsoft/swin-base-patch4-window12-384, Train Loss: 36.1070, Val Loss: 29.7477, Val MAE: 3.2897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:03<00:00,  6.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20, Model: microsoft/swin-base-patch4-window12-384, Train Loss: 62.8724, Val Loss: 71.0761, Val MAE: 4.8601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:05<00:00,  3.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20, Model: microsoft/swin-base-patch4-window12-384, Train Loss: 36.5880, Val Loss: 27.9277, Val MAE: 2.8856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:03<00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20, Model: microsoft/swin-base-patch4-window12-384, Train Loss: 61.9965, Val Loss: 72.1079, Val MAE: 5.0062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:05<00:00,  3.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20, Model: microsoft/swin-base-patch4-window12-384, Train Loss: 37.2901, Val Loss: 29.9963, Val MAE: 3.2192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:03<00:00,  6.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20, Model: microsoft/swin-base-patch4-window12-384, Train Loss: 60.0574, Val Loss: 69.8050, Val MAE: 4.7691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:05<00:00,  3.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20, Model: microsoft/swin-base-patch4-window12-384, Train Loss: 36.6846, Val Loss: 29.8946, Val MAE: 3.0834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:03<00:00,  6.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20, Model: microsoft/swin-base-patch4-window12-384, Train Loss: 61.6622, Val Loss: 70.8664, Val MAE: 5.0113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:05<00:00,  3.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20, Model: microsoft/swin-base-patch4-window12-384, Train Loss: 38.4431, Val Loss: 28.9947, Val MAE: 2.9612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:03<00:00,  6.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20, Model: microsoft/swin-base-patch4-window12-384, Train Loss: 61.4796, Val Loss: 69.8635, Val MAE: 4.7724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:05<00:00,  3.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20, Model: microsoft/swin-base-patch4-window12-384, Train Loss: 35.9261, Val Loss: 28.5490, Val MAE: 3.0948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:03<00:00,  6.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20, Model: microsoft/swin-base-patch4-window12-384, Train Loss: 63.4836, Val Loss: 69.0650, Val MAE: 4.7453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:05<00:00,  3.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20, Model: microsoft/swin-base-patch4-window12-384, Train Loss: 38.0803, Val Loss: 28.5137, Val MAE: 2.9250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:03<00:00,  6.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20, Model: microsoft/swin-base-patch4-window12-384, Train Loss: 63.5447, Val Loss: 70.6239, Val MAE: 4.8539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:05<00:00,  3.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20, Model: microsoft/swin-base-patch4-window12-384, Train Loss: 37.7125, Val Loss: 26.7612, Val MAE: 2.8519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:03<00:00,  6.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20, Model: microsoft/swin-base-patch4-window12-384, Train Loss: 68.0519, Val Loss: 70.6490, Val MAE: 4.9234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:05<00:00,  3.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20, Model: microsoft/swin-base-patch4-window12-384, Train Loss: 36.0058, Val Loss: 28.6489, Val MAE: 2.9828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shravan/anaconda3/envs/xeek_env/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/shravan/anaconda3/envs/xeek_env/lib/python3.10/site-packages/transformers/models/vit/feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
      "  warnings.warn(\n",
      "100%|███████████████████████████████████████████| 68/68 [00:03<00:00, 20.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted leaf counts saved to leaf_count_predictions.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoFeatureExtractor, SwinForImageClassification\n",
    "import random\n",
    "\n",
    "# Configuration setup\n",
    "class CFG:\n",
    "    seed = 42\n",
    "    batch_size = 8\n",
    "    num_epochs = 20  # Increased epochs for better training\n",
    "    model_names = [\"microsoft/swin-tiny-patch4-window7-224\", \"microsoft/swin-base-patch4-window12-384\"]\n",
    "    input_sizes = [(224, 224), (384, 384)]\n",
    "    learning_rate = 1e-4\n",
    "    lr_scheduler_step = 5  # Step size for LR scheduler\n",
    "    lr_scheduler_gamma = 0.1  # Multiplicative factor for LR decay\n",
    "\n",
    "# Set seed for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    print('> SEEDING DONE')\n",
    "\n",
    "set_seed(CFG.seed)\n",
    "\n",
    "# Define paths (update these paths according to your local setup)\n",
    "train_image_path = './rgb'\n",
    "leaf_count_path = 'leaf_count.csv'\n",
    "test_image_path = '../Test_data'\n",
    "\n",
    "# Load the leaf count CSV without headers\n",
    "leaf_count_df = pd.read_csv(leaf_count_path, header=None)\n",
    "print(\"Leaf count data without headers:\")\n",
    "print(leaf_count_df.head())\n",
    "\n",
    "# Assuming the first column is the image filename and the second column is the leaf count\n",
    "leaf_count_df.columns = ['image', 'leaf_count']\n",
    "print(\"Leaf count data with assigned headers:\")\n",
    "print(leaf_count_df.head())\n",
    "\n",
    "# Custom dataset class for loading images and leaf counts\n",
    "class LeafCountDataset(Dataset):\n",
    "    def __init__(self, image_files, leaf_counts, transform=None):\n",
    "        self.image_files = image_files\n",
    "        self.leaf_counts = leaf_counts\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = cv2.imread(self.image_files[idx])\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        leaf_count = torch.tensor(self.leaf_counts[idx], dtype=torch.float32)\n",
    "        return img, leaf_count\n",
    "\n",
    "# Get image files and corresponding leaf counts\n",
    "image_files = sorted(glob(os.path.join(train_image_path, '*.png')))\n",
    "leaf_counts = leaf_count_df['leaf_count'].values\n",
    "\n",
    "# Split into training and validation sets\n",
    "train_img_files, val_img_files, train_leaf_counts, val_leaf_counts = train_test_split(image_files, leaf_counts, test_size=0.2, random_state=CFG.seed)\n",
    "\n",
    "# Define transformations and create datasets and dataloaders\n",
    "train_datasets = []\n",
    "val_datasets = []\n",
    "train_loaders = []\n",
    "val_loaders = []\n",
    "\n",
    "for input_size, model_name in zip(CFG.input_sizes, CFG.model_names):\n",
    "    feature_extractor = AutoFeatureExtractor.from_pretrained(model_name)\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=feature_extractor.image_mean, std=feature_extractor.image_std),\n",
    "    ])\n",
    "    train_dataset = LeafCountDataset(train_img_files, train_leaf_counts, transform)\n",
    "    val_dataset = LeafCountDataset(val_img_files, val_leaf_counts, transform)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=CFG.batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=CFG.batch_size, shuffle=False)\n",
    "\n",
    "    train_datasets.append(train_dataset)\n",
    "    val_datasets.append(val_dataset)\n",
    "    train_loaders.append(train_loader)\n",
    "    val_loaders.append(val_loader)\n",
    "\n",
    "# Load models\n",
    "models = []\n",
    "optimizers = []\n",
    "schedulers = []\n",
    "\n",
    "for model_name in CFG.model_names:\n",
    "    model = SwinForImageClassification.from_pretrained(model_name)\n",
    "    model.classifier = nn.Linear(model.classifier.in_features, 1)  # Change the output layer to single regression value\n",
    "    model = model.to('cuda')\n",
    "    models.append(model)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=CFG.learning_rate)\n",
    "    optimizers.append(optimizer)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=CFG.lr_scheduler_step, gamma=CFG.lr_scheduler_gamma)\n",
    "    schedulers.append(scheduler)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Training function\n",
    "def train_model(models, train_loaders, val_loaders, criterion, optimizers, schedulers, num_epochs=10):\n",
    "    for epoch in range(num_epochs):\n",
    "        for model, train_loader, val_loader, optimizer, scheduler in zip(models, train_loaders, val_loaders, optimizers, schedulers):\n",
    "            model.train()\n",
    "            train_loss = 0.0\n",
    "\n",
    "            for images, leaf_counts in tqdm(train_loader):\n",
    "                images = images.to('cuda')\n",
    "                leaf_counts = leaf_counts.to('cuda')\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(images).logits.squeeze(1)  # Get the logits and squeeze the output to match leaf_counts shape\n",
    "                loss = criterion(outputs, leaf_counts)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                train_loss += loss.item() * images.size(0)\n",
    "\n",
    "            train_loss = train_loss / len(train_loader.dataset)\n",
    "            scheduler.step()\n",
    "\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            preds = []\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for images, leaf_counts in val_loader:\n",
    "                    images = images.to('cuda')\n",
    "                    leaf_counts = leaf_counts.to('cuda')\n",
    "\n",
    "                    outputs = model(images).logits.squeeze(1)\n",
    "                    loss = criterion(outputs, leaf_counts)\n",
    "                    val_loss += loss.item() * images.size(0)\n",
    "\n",
    "                    preds.extend(outputs.cpu().numpy())\n",
    "\n",
    "            val_loss = val_loss / len(val_loader.dataset)\n",
    "            val_mae = mean_absolute_error(val_leaf_counts, preds)\n",
    "\n",
    "            print(f'Epoch {epoch+1}/{num_epochs}, Model: {model_name}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val MAE: {val_mae:.4f}')\n",
    "\n",
    "train_model(models, train_loaders, val_loaders, criterion, optimizers, schedulers, num_epochs=CFG.num_epochs)\n",
    "\n",
    "# Save the trained models\n",
    "for model, model_name in zip(models, CFG.model_names):\n",
    "    sanitized_model_name = model_name.replace(\"/\", \"_\")\n",
    "    torch.save(model.state_dict(), f'{sanitized_model_name}_leaf_count.pth')\n",
    "\n",
    "# Function to predict and save results for the test set\n",
    "def predict_and_save_results(models, test_image_path, output_csv_path):\n",
    "    test_image_files = sorted(glob(os.path.join(test_image_path, '*.png')))\n",
    "    results = []\n",
    "\n",
    "    # Initialize feature extractors and transforms for each model\n",
    "    feature_extractors = [AutoFeatureExtractor.from_pretrained(model_name) for model_name in CFG.model_names]\n",
    "    transforms_list = [transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=feature_extractor.image_mean, std=feature_extractor.image_std),\n",
    "    ]) for input_size, feature_extractor in zip(CFG.input_sizes, feature_extractors)]\n",
    "\n",
    "    for img_file in tqdm(test_image_files):\n",
    "        img = cv2.imread(img_file)\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        model_preds = []\n",
    "\n",
    "        for model, transform in zip(models, transforms_list):\n",
    "            img_transformed = transform(img_rgb)\n",
    "            img_transformed = img_transformed.unsqueeze(0).to('cuda')\n",
    "\n",
    "            with torch.no_grad():\n",
    "                output = model(img_transformed).logits.cpu().numpy()[0, 0]\n",
    "                model_preds.append(output)\n",
    "\n",
    "        # Average predictions from all models and convert to integer\n",
    "        avg_pred = np.mean(model_preds)\n",
    "        results.append([os.path.basename(img_file), int(avg_pred)])\n",
    "\n",
    "    # Save results to CSV\n",
    "    results_df = pd.DataFrame(results, columns=['image', 'leaf_count'])\n",
    "    results_df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "# Predict and save results for the test set\n",
    "output_csv_path = 'leaf_count_predictions.csv'\n",
    "predict_and_save_results(models, test_image_path, output_csv_path)\n",
    "\n",
    "print(f\"Predicted leaf counts saved to {output_csv_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fc4ba1-b8e8-47a9-bca0-f3638106b1c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xeek_env",
   "language": "python",
   "name": "xeek_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
